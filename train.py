# -*- coding: utf-8 -*-
"""Train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zVRi3T12o0LdgmpYm7PrRN67osEHxwhr
"""

from keras.models import Sequential
from keras.layers import Dense, Masking, LSTM, Dropout
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import numpy as np
import tensorflow
import tensorflow as tf
from keras.optimizers import Adam
from keras import backend as K
import matplotlib.pyplot as plt
import pickle
from sklearn.externals import joblib

train_df = np.load('Robot_Trials_DL.npy')
y_train= train_df[:, :,[1]]
x_train= train_df[:, :,[0,2,3,4,5,6]]
train_data, other_d, train_labels, other_labels = train_test_split(x_train, y_train, test_size=0.20, random_state=42)
valid_data, test_data, valid_labels, test_labels = train_test_split(other_d, other_labels, test_size=0.30, random_state=42)

trainnp=np.array(train_data)
valnp=np.array(valid_data)
testnp=np.array(test_data)
nz = np.any(trainnp, -1)
nzz=np.any(valnp,-1)
nzzz=np.any(testnp,-1)
scalar = MinMaxScaler(feature_range=(-1,1))
trainnp[nz] = scalar.fit_transform(trainnp[nz])
valnp[nzz] = scalar.transform(valnp[nzz])
testnp[nzzz] = scalar.transform(testnp[nzzz])
scalerfile = 'scaler.sav'
pickle.dump(scalar, open(scalerfile, 'wb')) 
#plt.show

def MeanSquaredError(y_true, y_pred):
    zero = tf.constant(0, dtype='float32',name=None)
    where = tf.not_equal(y_true, zero)
    omit_zeros = tf.boolean_mask(y_true,where)
    indices = tf.where(where)
    result = tf.gather_nd(y_pred, indices)
    #print(omit_zeros)
    return K.mean(K.square(omit_zeros -(result)))


model = Sequential()
model.add(Masking(mask_value=0.0,input_shape=(700, 6)))
model.add(LSTM(256, activation='tanh',return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(32, activation='tanh', return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(32, activation='tanh', return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(32, activation='tanh', return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(32, activation='tanh', return_sequences=True))
model.add(Dropout(0.2))
model.add(Dense(1, activation='linear'))

model.compile(loss=MeanSquaredError, optimizer=Adam(lr=0.0015))
print(model.summary())

checkpoint = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss' ,patience=40), tf.keras.callbacks.ModelCheckpoint(filepath='model.h5', monitor='val_loss', verbose=1, save_weights_only=False, save_best_only=True, mode='min')]
model.fit(trainnp, train_labels, epochs=200, batch_size=32, validation_data=(valnp, valid_labels), callbacks=checkpoint)

load_model = tf.keras.models.load_model('model.h5')
pred = load_model.predict(testnp,batch_size=1)

for seq in range(len(test_labels)):
  for i in range(len(test_labels[seq,:,:])):
    if test_labels[seq,i,0] == 0:
      pred[seq,i:,:] = 0.0